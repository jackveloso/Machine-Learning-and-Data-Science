{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a convolutional neural network on the MNIST dataset via tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the mnist data set, and print the 5th test sample with its label as a one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "one-hot vector [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADGdJREFUeJzt3X/oXfV9x/HnW5cK2v5hUkyDyZYu\nyNiIYMdXHVHEMaxuVGLRSv1jZKw0/aOBFfbHxPxRYRRkrN3yVzTF0Cht2oK/QilrRIZuMiSJhJo2\naxtKTLOEpMEftWCISd7743tSvo3fe+4399e537yfDwj33vM5P94c8vp+zrnnnvOJzERSPVd0XYCk\nbhh+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtF/cEkNxYR/pxQGrPMjIXMN1TPHxH3RMTPIuJQ\nRDw8zLokTVYM+tv+iLgS+DlwF3AU2AM8lJk/bVnGnl8as0n0/LcAhzLzl5l5BvgusH6I9UmaoGHC\nfz3wqzmfjzbTfk9EbIyIvRGxd4htSRqxYb7wm+/Q4kOH9Zm5DdgGHvZL02SYnv8osGrO55XAseHK\nkTQpw4R/D3BDRHwyIj4CfB7YNZqyJI3bwIf9mXk2IjYBPwKuBLZn5k9GVpmksRr4Ut9AG/OcXxq7\nifzIR9LiZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtF\nGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRAw/RDRAR\nh4H3gHPA2cycGUVRunzce++9Pdt27drVuuymTZta2x9//PHW9nPnzrW2VzdU+Bt/mZmnRrAeSRPk\nYb9U1LDhT2B3ROyLiI2jKEjSZAx72H9bZh6LiOuAFyPifzPzlbkzNH8U/MMgTZmhev7MPNa8ngSe\nA26ZZ55tmTnjl4HSdBk4/BFxTUR87MJ74NPAgVEVJmm8hjnsXw48FxEX1vOdzPyPkVQlaewiMye3\nsYjJbUwTsWzZstb2/fv392xbuXLlUNu++uqrW9vff//9oda/WGVmLGQ+L/VJRRl+qSjDLxVl+KWi\nDL9UlOGXihrFXX0q7I477mhtH+Zy3s6dO1vbT58+PfC6Zc8vlWX4paIMv1SU4ZeKMvxSUYZfKsrw\nS0V5nV+trrrqqtb2zZs3j23bTz/9dGv7JG9HvxzZ80tFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUT66\nW61mZtoHWtqzZ8/A6z579mxr+5IlSwZed2U+ultSK8MvFWX4paIMv1SU4ZeKMvxSUYZfKqrv/fwR\nsR34DHAyM9c205YC3wNWA4eBBzPz7fGVqa7cf//9Y1v37t27x7Zu9beQnv9bwD0XTXsYeCkzbwBe\naj5LWkT6hj8zXwHeumjyemBH834HcN+I65I0ZoOe8y/PzOMAzet1oytJ0iSM/Rl+EbER2Dju7Ui6\nNIP2/CciYgVA83qy14yZuS0zZzKz/Q4RSRM1aPh3ARua9xuAF0ZTjqRJ6Rv+iNgJ/A/wJxFxNCK+\nADwG3BURvwDuaj5LWkS8n1+tXn311db2devWtbafOXOmZ9utt97auuz+/ftb2zU/7+eX1MrwS0UZ\nfqkowy8VZfilogy/VJSX+orrd6mu36W+ft5+u/ed3kuXLh1q3Zqfl/oktTL8UlGGXyrK8EtFGX6p\nKMMvFWX4paLG/hgvTbebb755rOvfunXrWNevwdnzS0UZfqkowy8VZfilogy/VJThl4oy/FJRXucv\nbmZmuIGU3nnnndZ2r/NPL3t+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyqq73P7I2I78BngZGaubaY9\nCnwR+HUz2yOZ+cO+G/O5/RN3++23t7a//PLLre1XXNHeP7z55put7atXr25t1+iN8rn93wLumWf6\nv2XmTc2/vsGXNF36hj8zXwHemkAtkiZomHP+TRHx44jYHhHXjqwiSRMxaPi3AmuAm4DjwNd7zRgR\nGyNib0TsHXBbksZgoPBn5onMPJeZ54FvAre0zLstM2cyc7g7SCSN1EDhj4gVcz5+FjgwmnIkTUrf\nW3ojYidwJ/DxiDgKfBW4MyJuAhI4DHxpjDVKGoO+4c/Mh+aZ/OQYatEYLFu2rLW933X8fl588cWh\nlld3/IWfVJThl4oy/FJRhl8qyvBLRRl+qSgf3X2Ze+CBB4Zavt+juZ944omh1q/u2PNLRRl+qSjD\nLxVl+KWiDL9UlOGXijL8UlF9H9090o356O6xWLlyZc+2fo/W7ndL74ED7c9pufHGG1vbNXmjfHS3\npMuQ4ZeKMvxSUYZfKsrwS0UZfqkowy8V5f38l4F169b1bBv20dzPP//8UMtretnzS0UZfqkowy8V\nZfilogy/VJThl4oy/FJRfa/zR8Qq4CngE8B5YFtmbomIpcD3gNXAYeDBzHx7fKWql37DcLc5depU\na/uWLVsGXrem20J6/rPAP2bmnwJ/AXw5Iv4MeBh4KTNvAF5qPktaJPqGPzOPZ+brzfv3gIPA9cB6\nYEcz2w7gvnEVKWn0LumcPyJWA58CXgOWZ+ZxmP0DAVw36uIkjc+Cf9sfER8FngG+kpm/iVjQY8KI\niI3AxsHKkzQuC+r5I2IJs8H/dmY+20w+ERErmvYVwMn5ls3MbZk5k5kzoyhY0mj0DX/MdvFPAgcz\n8xtzmnYBG5r3G4AXRl+epHFZyGH/bcDfAm9ExP5m2iPAY8D3I+ILwBHgc+MpUf3cfffdAy975MiR\n1vZ333134HVruvUNf2b+N9DrBP+vRluOpEnxF35SUYZfKsrwS0UZfqkowy8VZfilonx09yKwZMmS\n1vY1a9YMvO7Tp0+3tn/wwQcDr1vTzZ5fKsrwS0UZfqkowy8VZfilogy/VJThl4ryOv8icP78+db2\nvXv39mxbu3Zt67KHDh0aqCYtfvb8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU1/kXgXPnzrW2b968\nuWdbZrYuu2/fvoFq0uJnzy8VZfilogy/VJThl4oy/FJRhl8qyvBLRUW/68ARsQp4CvgEcB7Ylplb\nIuJR4IvAr5tZH8nMH/ZZV/vGJA0tM2Mh8y0k/CuAFZn5ekR8DNgH3Ac8CPw2M/91oUUZfmn8Fhr+\nvr/wy8zjwPHm/XsRcRC4frjyJHXtks75I2I18CngtWbSpoj4cURsj4hreyyzMSL2RkTvZ01Jmri+\nh/2/mzHio8DLwNcy89mIWA6cAhL4Z2ZPDf6+zzo87JfGbGTn/AARsQT4AfCjzPzGPO2rgR9kZuvT\nIg2/NH4LDX/fw/6ICOBJ4ODc4DdfBF7wWeDApRYpqTsL+bb/duC/gDeYvdQH8AjwEHATs4f9h4Ev\nNV8Otq3Lnl8as5Ee9o+K4ZfGb2SH/ZIuT4ZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8q\nyvBLRRl+qSjDLxVl+KWiJj1E9yngzTmfP95Mm0bTWtu01gXWNqhR1vZHC51xovfzf2jjEXszc6az\nAlpMa23TWhdY26C6qs3Dfqkowy8V1XX4t3W8/TbTWtu01gXWNqhOauv0nF9Sd7ru+SV1pJPwR8Q9\nEfGziDgUEQ93UUMvEXE4It6IiP1dDzHWDIN2MiIOzJm2NCJejIhfNK/zDpPWUW2PRsT/Nftuf0T8\nTUe1rYqI/4yIgxHxk4j4h2Z6p/uupa5O9tvED/sj4krg58BdwFFgD/BQZv50ooX0EBGHgZnM7Pya\ncETcAfwWeOrCaEgR8S/AW5n5WPOH89rM/Kcpqe1RLnHk5jHV1mtk6b+jw303yhGvR6GLnv8W4FBm\n/jIzzwDfBdZ3UMfUy8xXgLcumrwe2NG838Hsf56J61HbVMjM45n5evP+PeDCyNKd7ruWujrRRfiv\nB3415/NRpmvI7wR2R8S+iNjYdTHzWH5hZKTm9bqO67lY35GbJ+mikaWnZt8NMuL1qHUR/vlGE5mm\nSw63ZeafA38NfLk5vNXCbAXWMDuM23Hg610W04ws/Qzwlcz8TZe1zDVPXZ3sty7CfxRYNefzSuBY\nB3XMKzOPNa8ngeeYPU2ZJicuDJLavJ7suJ7fycwTmXkuM88D36TDfdeMLP0M8O3MfLaZ3Pm+m6+u\nrvZbF+HfA9wQEZ+MiI8Anwd2dVDHh0TENc0XMUTENcCnmb7Rh3cBG5r3G4AXOqzl90zLyM29Rpam\n4303bSNed/Ijn+ZSxr8DVwLbM/NrEy9iHhHxx8z29jB7x+N3uqwtInYCdzJ719cJ4KvA88D3gT8E\njgCfy8yJf/HWo7Y7ucSRm8dUW6+RpV+jw303yhGvR1KPv/CTavIXflJRhl8qyvBLRRl+qSjDLxVl\n+KWiDL9UlOGXivp/MCm0EPr9ARwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c9914a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "print('one-hot vector', mnist.test.labels[5])\n",
    "plt.imshow(mnist.test.images[5].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling of the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the placeholders, and for convenience sake we define a 2d convolution an a max poolong function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"data\")\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define initialization as function (because we will need this for each layer...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the first layer with 32 convolutional nodes, with filterdimension 5x5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation layer + pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the second hidden convolutinal layer (of size 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a first fully connected layer of size 1024 with its activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply dropout in readout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define readout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.84\n",
      "step 200, training accuracy 0.82\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.98\n",
      "step 900, training accuracy 0.94\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 0.96\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.98\n",
      "step 1500, training accuracy 0.98\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 0.92\n",
      "step 1800, training accuracy 0.94\n",
      "step 1900, training accuracy 0.96\n",
      "step 2000, training accuracy 0.96\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.98\n",
      "step 2300, training accuracy 0.94\n",
      "step 2400, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2500):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9796\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8E9R8JmxpgouxFLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c83f0f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9990904e-01 1.3474050e-07 3.7892372e-05 6.6380062e-07 2.5134108e-08\n",
      "  1.3210055e-06 2.9327346e-05 7.4540608e-08 9.8758173e-06 1.1581610e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "plt.imshow(mnist.test.images[10].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()\n",
    "Z = y_conv.eval(feed_dict={x: mnist.test.images[10].reshape(1, 784), keep_prob: 1})\n",
    "print(sess.run(tf.nn.softmax(Z)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a prediction of 99.99 % that the digit in this image is a 0 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
